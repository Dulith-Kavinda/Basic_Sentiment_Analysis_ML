# IMDB Sentiment Analysis

A deep learning project for sentiment analysis of movie reviews using LSTM neural networks with TensorFlow/Keras.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Dataset](#dataset)
- [Model Architecture](#model-architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Results](#results)
- [Project Structure](#project-structure)
- [Hyperparameter Optimization](#hyperparameter-optimization)
- [Technical Details](#technical-details)
- [Future Improvements](#future-improvements)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project implements a binary sentiment classifier for movie reviews using deep learning. The model analyzes text reviews and predicts whether they express positive or negative sentiment. Built with TensorFlow and Keras, it employs LSTM (Long Short-Term Memory) networks to capture sequential patterns in text data.

## âœ¨ Features

- **Advanced Text Preprocessing**: URL removal, number stripping, special character handling
- **LSTM Architecture**: Dual-layer LSTM for capturing long-range dependencies
- **Regularization Techniques**: Dropout layers and L2 regularization to prevent overfitting
- **Early Stopping**: Automatic training termination to optimize performance
- **Hyperparameter Optimization**: Data-driven analysis to find optimal model parameters
- **Visualization**: Training/validation metrics plotting for performance monitoring
- **Model Persistence**: Save and load trained models for deployment

## ğŸ“Š Dataset

- **Source**: `finalReviews.csv`
- **Total Records**: 301 reviews
- **Features**: 
  - `review`: Text of the movie review
  - `label`: Binary sentiment (0 = negative, 1 = positive)
- **Train/Test Split**: 80/20 (241 training, 60 testing)
- **Vocabulary Size**: 2,930 unique tokens

### Data Statistics

- **Sequence Length**:
  - Min: 1 token
  - Max: 618 tokens
  - Mean: 71.41 tokens
  - Median: 31 tokens
  - 95th percentile: 305 tokens

## ğŸ—ï¸ Model Architecture

```
Sequential Model:
â”œâ”€â”€ Embedding Layer (3000 vocab Ã— 64 dimensions)
â”œâ”€â”€ LSTM Layer (64 units, return_sequences=True, dropout=0.2)
â”œâ”€â”€ LSTM Layer (32 units, dropout=0.2)
â”œâ”€â”€ Dense Layer (64 units, ReLU, L2 regularization)
â”œâ”€â”€ Dropout (0.3)
â”œâ”€â”€ Dense Layer (32 units, ReLU, L2 regularization)
â”œâ”€â”€ Dropout (0.3)
â””â”€â”€ Output Layer (1 unit, Sigmoid)
```

### Key Parameters

- **Max Words**: 3,000 (100% vocabulary coverage)
- **Max Length**: 90 tokens (covers ~95% of sequences)
- **Embedding Dimension**: 64
- **Optimizer**: Adam (learning_rate=0.001)
- **Loss Function**: Binary Crossentropy
- **Batch Size**: 32
- **Max Epochs**: 25 (with early stopping)

## ğŸš€ Installation

### Prerequisites

- Python 3.8+
- pip package manager

### Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd HTB
   ```

2. **Install required packages**
   ```bash
   pip install numpy pandas tensorflow matplotlib scikit-learn
   ```

3. **Verify installation**
   ```bash
   python -c "import tensorflow as tf; print(tf.__version__)"
   ```

### Dependencies

```
numpy>=1.21.0
pandas>=1.3.0
tensorflow>=2.10.0
matplotlib>=3.4.0
scikit-learn>=0.24.0
```

## ğŸ’» Usage

### Training the Model

1. **Open the Jupyter Notebook**
   ```bash
   jupyter notebook Imdb_sentiment_analysis.ipynb
   ```

2. **Run all cells sequentially** or execute specific sections:
   - Data loading and preprocessing
   - Text cleaning and tokenization
   - Model training
   - Evaluation and visualization

### Making Predictions

```python
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle

# Load the trained model
model = tf.keras.models.load_model('sentiment_model.keras')

# Load tokenizer (save it during training)
# tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))

# Prepare new review
new_review = "This movie was absolutely fantastic! Great acting and plot."
new_review_seq = tokenizer.texts_to_sequences([new_review])
new_review_pad = pad_sequences(new_review_seq, maxlen=90, padding='post')

# Predict
prediction = model.predict(new_review_pad)
sentiment = "Positive" if prediction[0][0] > 0.5 else "Negative"
confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]

print(f"Sentiment: {sentiment} (Confidence: {confidence:.2%})")
```

## ğŸ“ˆ Results

### Model Performance

| Metric | Training | Validation | Test |
|--------|----------|------------|------|
| **Accuracy** | 70.31% | 61.22% | 63.93% |
| **Loss** | 0.5913 | 0.7082 | 0.6907 |

### Overfitting Analysis

- **Train-Val Loss Difference**: -0.1170 (Moderate overfitting)
- **Early Stopping**: Activated at optimal validation performance
- **Generalization**: Test accuracy aligns well with validation accuracy

### Training Characteristics

- **Convergence**: Achieved within 10-15 epochs
- **Stability**: Smooth loss curves with minimal oscillation
- **Efficiency**: ~10-11 seconds total training time

## ğŸ“ Project Structure

```
/
â”œâ”€â”€ Imdb_sentiment_analysis.ipynb  # Main notebook with complete pipeline
â”œâ”€â”€ finalReviews.csv               # Dataset
â”œâ”€â”€ sentiment_model.keras          # Saved trained model
â”œâ”€â”€ README.md                      # This file

## ğŸ”§ Hyperparameter Optimization

The project includes automated hyperparameter analysis:

### Tested Configurations

| max_len | max_words | Train Size | Model Params | Notes |
|---------|-----------|------------|--------------|-------|
| 50 | 500 | 0.05 MB | 79,168 | Low vocab (17.1%) |
| 80 | 1000 | 0.07 MB | 111,168 | Low vocab (34.1%) |
| 150 | 2000 | 0.14 MB | 175,168 | Balanced |
| 200 | 2500 | 0.18 MB | 207,168 | Good coverage |
| **90** | **3000** | **0.08 MB** | **239,168** | **OPTIMAL âœ“** |
| 300 | 3000 | 0.28 MB | 239,168 | Over-parameterized |

### Selection Criteria

- **Vocabulary Coverage**: 100% (all 2,930 tokens)
- **Sequence Coverage**: ~95% of all review lengths
- **Model Size**: Balanced (not too large to overfit)
- **Performance**: Best validation accuracy

## ğŸ” Technical Details

### Text Preprocessing Pipeline

1. **URL Removal**: Strips all HTTP/HTTPS links
2. **Number Removal**: Eliminates numeric characters
3. **Special Character Filtering**: Keeps only alphanumeric and basic punctuation
4. **Whitespace Normalization**: Removes extra spaces
5. **Tokenization**: Converts text to integer sequences
6. **Padding**: Standardizes sequence length to 90 tokens

### Regularization Strategies

1. **Dropout Layers**: 20% in LSTM, 30% in dense layers
2. **L2 Regularization**: 0.001 weight penalty on dense layers
3. **Early Stopping**: Patience of 3 epochs on validation loss
4. **Validation Split**: 20% of training data for monitoring

### Model Training Process

```python
# Early Stopping Configuration
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

# Training
history = model.fit(
    x_train_pad, y_train_arr,
    epochs=25,
    validation_split=0.2,
    batch_size=32,
    callbacks=[early_stopping]
)
```

## ğŸš€ Future Improvements

### Model Enhancements

- [ ] Implement Bidirectional LSTM for better context understanding
- [ ] Try GRU (Gated Recurrent Units) as an alternative to LSTM
- [ ] Experiment with Transformer-based models (BERT, DistilBERT)
- [ ] Add attention mechanisms for interpretability
- [ ] Ensemble multiple models for improved accuracy

### Data Augmentation

- [ ] Collect more training data
- [ ] Implement back-translation for data augmentation
- [ ] Use synonym replacement
- [ ] Apply text generation techniques

### Feature Engineering

- [ ] Add pre-trained word embeddings (GloVe, Word2Vec)
- [ ] Include sentiment lexicon features
- [ ] Extract n-gram features
- [ ] Incorporate part-of-speech tagging

### Deployment

- [ ] Create REST API using Flask/FastAPI
- [ ] Build web interface for interactive predictions
- [ ] Containerize with Docker
- [ ] Deploy to cloud platform (AWS, GCP, Azure)
- [ ] Create mobile app interface

### Analysis & Monitoring

- [ ] Add confusion matrix visualization
- [ ] Implement ROC curve and AUC metrics
- [ ] Create word importance visualization
- [ ] Add model explanation (LIME, SHAP)
- [ ] Set up MLflow for experiment tracking

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Contribution Guidelines

- Follow PEP 8 style guidelines for Python code
- Add docstrings to all functions and classes
- Include unit tests for new features
- Update documentation accordingly
- Ensure all tests pass before submitting PR

## ğŸ“ License

This project is licensed under the MIT License - see the MIT(LICENSE) file for details.


## ğŸ™ Acknowledgments

- TensorFlow/Keras team for the deep learning framework
- IMDB for the dataset
- The open-source community for various tools and libraries

## ğŸ“ Contact

For questions or feedback, please open an issue or contact:
- Email: your.email@example.com
- GitHub: [@Dulith-Kavinda](https://github.com/Dulith-Kavinda)

---

**Last Updated**: January 20, 2026

**Status**: Active Development ğŸš§
